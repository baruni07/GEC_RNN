{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "220d98d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6273796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# from torch.utils.data import DataLoader,Dataset,WeightedRandomSampler\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext.legacy.data import TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "7681c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from seqeval.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55e91660",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a6a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = 'ptrain.jsonl'\n",
    "# with open(train_path) as f:\n",
    "#     train_data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b641159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_path = 'val.jsonl'\n",
    "# with open(val_path) as f:\n",
    "#     val_data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d7f141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_use = copy.deepcopy(train_data)\n",
    "\n",
    "# val_data_use = copy.deepcopy(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f49b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def removeUnwanted(data_set):\n",
    "#     for each in data_set:\n",
    "#         each['tokens'].pop(0)\n",
    "#         each['tokens'].pop()\n",
    "\n",
    "#         each['labels'].pop(0)\n",
    "#         each['labels'].pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9d586b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removeUnwanted(train_data_use)\n",
    "# removeUnwanted(val_data_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f4266ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = Field(lower = True, pad_token = '<pad>', unk_token = '<unk>', batch_first = True, use_vocab = True, fix_length = 49)\n",
    "labels = Field(pad_token = '<pad>', unk_token = '<unk>', batch_first = True, use_vocab = True, fix_length = 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "eb58c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {'tokens':('tokens',tokens), 'labels':('labels', labels)}\n",
    "train_dataset, val_dataset, test_dataset = TabularDataset.splits(path = \"./\", format = \"json\", \n",
    "                                                                 train = \"ptrain_topk_overfit.jsonl\", \n",
    "                                                                 validation = \"val_topk_overfit.jsonl\", \n",
    "                                                                 test = \"test_topk.jsonl\", \n",
    "                                                                 fields = fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5fb483a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "# train_dataset = train_dataset[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8f7fb7c8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mr',\n",
       " 'charnley',\n",
       " 'said',\n",
       " 'either',\n",
       " 'the',\n",
       " 'council',\n",
       " 'was',\n",
       " 'also',\n",
       " 'considering',\n",
       " 'up',\n",
       " 'whether',\n",
       " 'to',\n",
       " 'install',\n",
       " 'speed',\n",
       " 'the',\n",
       " 'cameras',\n",
       " 'along',\n",
       " 'the',\n",
       " 'road',\n",
       " ',']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9b9f77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.build_vocab(train_dataset, vectors = \"glove.6B.50d\")\n",
    "labels.build_vocab(train_dataset, vectors = \"glove.6B.50d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "230c931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens.vocab.vectors.shape = torch.Size([1131, 50])\n",
      "edits.vocab.vectors.shape = torch.Size([22, 50])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"tokens.vocab.vectors.shape = {tokens.vocab.vectors.shape}\")\n",
    "print(f\"edits.vocab.vectors.shape = {labels.vocab.vectors.shape}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bb6e237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens.vocab.itos[0] = <pad>\n",
      "tokens.vocab.stoi['the'] = 0\n",
      "edits.vocab.stoi['$keep'] = 2\n",
      "edits.vocab.itos[0] = $KEEP\n",
      "edits.vocab.stoi[' '] = 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"tokens.vocab.itos[0] = {tokens.vocab.itos[1]}\")\n",
    "print(f\"tokens.vocab.stoi['the'] = {tokens.vocab.stoi['body']}\")\n",
    "print(f\"edits.vocab.stoi['$keep'] = {labels.vocab.stoi['$KEEP']}\")\n",
    "print(f\"edits.vocab.itos[0] = {labels.vocab.itos[2]}\")\n",
    "print(f\"edits.vocab.stoi[' '] = {labels.vocab.stoi[' ']}\")\n",
    "# index 0: <unk> , 1:<pad> for both labels and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "75b5e8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokens.vocab.freqs.keys()) = 1129\n",
      "len(edits.vocab.freqs.keys()) = 20 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'$KEEP': 2122,\n",
       "         '$DELETE': 70,\n",
       "         '$REPLACE_.': 16,\n",
       "         '$REPLACE_of': 5,\n",
       "         '$APPEND_.': 10,\n",
       "         '$REPLACE_,': 14,\n",
       "         '$TRANSFORM_AGREEMENT_SINGULAR': 11,\n",
       "         '$APPEND_the': 10,\n",
       "         '$REPLACE_to': 8,\n",
       "         '$APPEND_to': 4,\n",
       "         '$APPEND_,': 10,\n",
       "         '$REPLACE_the': 5,\n",
       "         '$TRANSFORM_VERB_VBN_VB': 5,\n",
       "         '$REPLACE_in': 1,\n",
       "         '$TRANSFORM_VERB_VBZ_VB': 4,\n",
       "         '$APPEND_of': 2,\n",
       "         '$APPEND_a': 5,\n",
       "         '$TRANSFORM_VERB_VBG_VB': 1,\n",
       "         '$APPEND_and': 2,\n",
       "         '$TRANSFORM_AGREEMENT_PLURAL': 3})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"len(tokens.vocab.freqs.keys()) = {len(tokens.vocab.freqs.keys())}\")  #doesnt include <pad> and <unk> token\n",
    "print(f\"len(edits.vocab.freqs.keys()) = {len(labels.vocab.freqs.keys())} \\n\") #doesnt include <pad> and <unk> token\n",
    "c1 = labels.vocab.freqs\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "5da17370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(pred, y):\n",
    "\n",
    "    pred_1 = torch.argmax(pred, dim = 1)\n",
    "    #(N,49)\n",
    "    N = pred_1.size(0)\n",
    "    \n",
    "    acc = 0.0\n",
    "    \n",
    "    for i in range(N):\n",
    "\n",
    "        c = y[i] == 1   #geting sentence length (find first padding value so we can trime it from there)\n",
    "        c = c.nonzero()\n",
    "        try:\n",
    "            sent_len = c[0].item()\n",
    "        except:\n",
    "            sent_len = len(y[i]) - 1\n",
    "        \n",
    "        use_y = y[i][:sent_len + 1]\n",
    "        use_pred = pred_1[i][:sent_len+1]\n",
    "        \n",
    "        acc += accuracy_score(use_y, use_pred).item()\n",
    "        \n",
    "#         acc += accuracy_score(y[i], pred_1[i]).item()\n",
    "    \n",
    "    return acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "9ab66266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, optimizer, loss_fn, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    for batch, dat in enumerate(train_dataloader):\n",
    "        X = dat.tokens\n",
    "        y = dat.labels\n",
    "        #move to GPU\n",
    "        X,y = X.to(device), y.to(device)\n",
    "\n",
    "        \n",
    "        # Compute prediction error\n",
    "        pred,_ = model(X)\n",
    "\n",
    "#         print(pred.size(), \" pred shpe\")\n",
    "#         print(\"y size: \", y.size())\n",
    "        \n",
    "        \n",
    "        loss = loss_fn(pred, y)\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += getAccuracy(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        #UNCOMMENT\n",
    "#         if batch%50 == 49:\n",
    "        if batch%2 == 1:\n",
    "            print(\"BATCH: \", batch, \" LOSS: \", loss.item())\n",
    "            writer.add_scalar('training loss batchwise',\n",
    "                                    train_loss / batch,\n",
    "                                    epoch * len(train_dataloader) + batch)\n",
    "\n",
    "    train_loss = train_loss/len(train_dataloader)\n",
    "    \n",
    "#     print(\"ret: \", ret)\n",
    "    train_accuracy = (100. * train_accuracy) / len(train_dataloader.dataset)\n",
    "    \n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f1606388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_dataloader,loss_fn):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for dat in val_dataloader:\n",
    "            X = dat.tokens\n",
    "            y = dat.labels\n",
    "            \n",
    "            #move to GPU\n",
    "            X,y = X.to(device), y.to(device)\n",
    "        \n",
    "            pred,_ = model(X)\n",
    "\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_accuracy += getAccuracy(pred, y)\n",
    "            \n",
    "\n",
    "    avg_val_loss = val_loss/len(val_dataloader)\n",
    "\n",
    "    val_accuracy = (100.* val_accuracy) / len(val_dataloader.dataset)\n",
    "    \n",
    "    return avg_val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "33ad145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, embed_dim,hidden_dim, n_classes, vocab_size, pad_idx, embedd_weights):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(embedd_weights, padding_idx = pad_idx, freeze = True)\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size = embed_dim, hidden_size = hidden_dim, num_layers = 2, bidirectional = True, batch_first=True)\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_dim*2, n_classes)  #when using bidirectional rnn\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x)\n",
    "        #(N,L,embed_dim)\n",
    "#         print(\"X: \", x.size())\n",
    "        \n",
    "        op1, h_n = self.rnn(x)\n",
    "#         print(\"op1: \", op1.size(), \" h_n: \", h_n.size())\n",
    "        #op1 (N,L,n_classes)\n",
    "        \n",
    "#         op2 = op1.view(-1, self.embed_dim)\n",
    "#         print(\"op2: \", op2.size())\n",
    "        #op2 (N*L, embed_dim)\n",
    "        \n",
    "        op1 = self.linear(op1)\n",
    "\n",
    "        op1 = torch.transpose(op1, 1,2)\n",
    "        # (N,n_classes, L) -- needed for crossentropy\n",
    "#         print(\"op1: \", op1.size())\n",
    "        \n",
    "        \n",
    "        return op1, h_n\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "82e2e87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "d938380b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_dataset = train_dataset[:100]\n",
    "# val_dataset = val_dataset[:50]\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "b9f5857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_dataloader, val_dataloader= BucketIterator.splits((train_dataset, val_dataset), batch_size = batch_size, device = device, \n",
    "                                 sort_key=lambda x: len(x.tokens), sort_within_batch = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "85e1e3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorchText BuketIterator\n",
      "\n",
      "Batch size: 4\n",
      "\n",
      "LABEL\tLENGTH\tTEXT\n",
      "44\t       \n",
      "45\t       \n",
      "45\t       \n",
      "49\t       \n",
      "\n",
      "\n",
      "Batch size: 16\n",
      "\n",
      "LABEL\tLENGTH\tTEXT\n",
      "26\t       \n",
      "26\t       \n",
      "26\t       \n",
      "27\t       \n",
      "27\t       \n",
      "28\t       \n",
      "28\t       \n",
      "29\t       \n",
      "29\t       \n",
      "29\t       \n",
      "29\t       \n",
      "30\t       \n",
      "30\t       \n",
      "30\t       \n",
      "30\t       \n",
      "30\t       \n",
      "\n",
      "\n",
      "Batch size: 16\n",
      "\n",
      "LABEL\tLENGTH\tTEXT\n",
      "14\t       \n",
      "15\t       \n",
      "15\t       \n",
      "15\t       \n",
      "15\t       \n",
      "16\t       \n",
      "16\t       \n",
      "17\t       \n",
      "17\t       \n",
      "17\t       \n",
      "17\t       \n",
      "17\t       \n",
      "17\t       \n",
      "18\t       \n",
      "18\t       \n",
      "18\t       \n",
      "\n",
      "\n",
      "Batch size: 16\n",
      "\n",
      "LABEL\tLENGTH\tTEXT\n",
      "21\t       \n",
      "21\t       \n",
      "21\t       \n",
      "23\t       \n",
      "23\t       \n",
      "23\t       \n",
      "23\t       \n",
      "23\t       \n",
      "24\t       \n",
      "24\t       \n",
      "24\t       \n",
      "24\t       \n",
      "24\t       \n",
      "24\t       \n",
      "25\t       \n",
      "25\t       \n",
      "\n",
      "\n",
      "Batch size: 16\n",
      "\n",
      "LABEL\tLENGTH\tTEXT\n",
      "18\t       \n",
      "18\t       \n",
      "18\t       \n",
      "19\t       \n",
      "19\t       \n",
      "19\t       \n",
      "19\t       \n",
      "19\t       \n",
      "19\t       \n",
      "20\t       \n",
      "20\t       \n",
      "21\t       \n",
      "21\t       \n",
      "21\t       \n",
      "21\t       \n",
      "21\t       \n",
      "\n",
      "\n",
      "Batch size: 16\n",
      "\n",
      "LABEL\tLENGTH\tTEXT\n",
      "31\t       \n",
      "32\t       \n",
      "32\t       \n",
      "32\t       \n",
      "32\t       \n",
      "32\t       \n",
      "33\t       \n",
      "34\t       \n",
      "34\t       \n",
      "34\t       \n",
      "35\t       \n",
      "35\t       \n",
      "35\t       \n",
      "41\t       \n",
      "41\t       \n",
      "41\t       \n",
      "\n",
      "\n",
      "Batch size: 16\n",
      "\n",
      "LABEL\tLENGTH\tTEXT\n",
      "5\t       \n",
      "7\t       \n",
      "9\t       \n",
      "9\t       \n",
      "10\t       \n",
      "10\t       \n",
      "10\t       \n",
      "10\t       \n",
      "11\t       \n",
      "12\t       \n",
      "12\t       \n",
      "13\t       \n",
      "13\t       \n",
      "13\t       \n",
      "13\t       \n",
      "13\t       \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataloader.create_batches()\n",
    "\n",
    "# Loop through BucketIterator.\n",
    "print('PyTorchText BuketIterator\\n')\n",
    "for batch in train_dataloader.batches:\n",
    "\n",
    "    # Let's check batch size.\n",
    "    print('Batch size: %d\\n'% len(batch))\n",
    "    print('LABEL\\tLENGTH\\tTEXT'.ljust(10))\n",
    "  \n",
    "  # Print each example.\n",
    "    for example in batch:\n",
    "        print('%d\\t'.ljust(10) % (len(example.tokens)))\n",
    "#         print(\"here: \", example.labels)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "#     print(batch.tokens)\n",
    "  \n",
    "  # Only look at first batch. Reuse this code in training models.\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "47ca617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(train_dataloader))\n",
    "# batch.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "dd67a2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2, 13,  2,  2,  2,\n",
      "         2,  2,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "for each in batch:\n",
    "    print(each[1][0])   #[1] - labels , [0] - first example\n",
    "    print(len(each[1][0]))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "ab21bcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1131, 50])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = tokens.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "13b26777",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "MX_LEN_SEN = 49   #####CHANGE TO mx_len_for_pad  AFTER CHECKING FOR OVERFITTING\n",
    "n_classes = len(labels.vocab)\n",
    "vocab_size = len(tokens.vocab)\n",
    "pad_idx = tokens.vocab.stoi[tokens.pad_token]\n",
    "hidden_dim = n_classes\n",
    "\n",
    "model = SimpleRNN(EMBEDDING_DIM, hidden_dim, n_classes, vocab_size, pad_idx, pretrained_embeddings).to(device)\n",
    "\n",
    "lr = 0.01\n",
    "weight_decay = 0.001\n",
    "amsgrad = False\n",
    "# class_weights = class_weights\n",
    "ignore_index = 1\n",
    "# class_weights_des = 'method 2'\n",
    "\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr , weight_decay = weight_decay, amsgrad = amsgrad)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index = ignore_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "83ea7c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)  #copying the embedding matrix for embedding layer of model\n",
    "\n",
    "UNK_IDX = tokens.vocab.stoi[tokens.unk_token]  #this doesnt include pad and unk token so we r initializing that as well\n",
    "PAD_IDX = tokens.vocab.stoi[tokens.pad_token] \n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "4d2fbedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# CHANGE EVERY TIME U CHANGE HYPERPARAMETERS\n",
    "writer = SummaryWriter('rnn_runs/exp3_trial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "b0500c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH:  1  LOSS:  2.2657148838043213\n",
      "BATCH:  3  LOSS:  1.0584861040115356\n",
      "BATCH:  5  LOSS:  0.32621344923973083\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  0\n",
      "train_loss:  1.3359597538198744  train_accuracy:  71.51307164132595\n",
      "val_loss:  0.5732477381825447  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.26775190234184265\n",
      "BATCH:  3  LOSS:  0.6906896829605103\n",
      "BATCH:  5  LOSS:  1.0083794593811035\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  1\n",
      "train_loss:  0.5649869740009308  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.6188370101153851  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.6625056266784668\n",
      "BATCH:  3  LOSS:  0.3678681552410126\n",
      "BATCH:  5  LOSS:  0.4778642952442169\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  2\n",
      "train_loss:  0.5480254973684039  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.590992871671915  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.36446061730384827\n",
      "BATCH:  3  LOSS:  0.45885148644447327\n",
      "BATCH:  5  LOSS:  0.6116896867752075\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  3\n",
      "train_loss:  0.5222273468971252  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5792692936956882  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.4455755650997162\n",
      "BATCH:  3  LOSS:  0.3065650165081024\n",
      "BATCH:  5  LOSS:  0.3646450936794281\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  4\n",
      "train_loss:  0.5140136310032436  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5555081106722355  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.2888718843460083\n",
      "BATCH:  3  LOSS:  0.44548532366752625\n",
      "BATCH:  5  LOSS:  0.3512575030326843\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  5\n",
      "train_loss:  0.5038220158645085  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5449782609939575  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.35824325680732727\n",
      "BATCH:  3  LOSS:  0.611900269985199\n",
      "BATCH:  5  LOSS:  0.42886263132095337\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  6\n",
      "train_loss:  0.5102225371769497  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.542603399604559  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.4211098551750183\n",
      "BATCH:  3  LOSS:  0.35311591625213623\n",
      "BATCH:  5  LOSS:  0.28398895263671875\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  7\n",
      "train_loss:  0.5031387550490243  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5487107187509537  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.5890399217605591\n",
      "BATCH:  3  LOSS:  0.4190067946910858\n",
      "BATCH:  5  LOSS:  0.45008939504623413\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  8\n",
      "train_loss:  0.5043233377592904  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5439247749745846  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.812170147895813\n",
      "BATCH:  3  LOSS:  0.2964252829551697\n",
      "BATCH:  5  LOSS:  0.5663167238235474\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  9\n",
      "train_loss:  0.5030638149806431  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5406909957528114  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.5824175477027893\n",
      "BATCH:  3  LOSS:  0.4192506968975067\n",
      "BATCH:  5  LOSS:  0.6569960117340088\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  10\n",
      "train_loss:  0.5046962542193276  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5429197587072849  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.6337442398071289\n",
      "BATCH:  3  LOSS:  0.43325576186180115\n",
      "BATCH:  5  LOSS:  0.3061487674713135\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  11\n",
      "train_loss:  0.5079330078193119  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5428778193891048  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.42156684398651123\n",
      "BATCH:  3  LOSS:  0.2827233076095581\n",
      "BATCH:  5  LOSS:  0.3482479453086853\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  12\n",
      "train_loss:  0.5055237114429474  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5516677871346474  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.41632384061813354\n",
      "BATCH:  3  LOSS:  0.6437903046607971\n",
      "BATCH:  5  LOSS:  0.5564178824424744\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  13\n",
      "train_loss:  0.507002170596804  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5438101999461651  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.4039255678653717\n",
      "BATCH:  3  LOSS:  0.8131446242332458\n",
      "BATCH:  5  LOSS:  0.4202670753002167\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  14\n",
      "train_loss:  0.5023328236171177  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5444624125957489  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.40249404311180115\n",
      "BATCH:  3  LOSS:  0.5599572658538818\n",
      "BATCH:  5  LOSS:  0.8332326412200928\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  15\n",
      "train_loss:  0.5013852034296308  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5414809137582779  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.8235757946968079\n",
      "BATCH:  3  LOSS:  0.6291114687919617\n",
      "BATCH:  5  LOSS:  0.434134840965271\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  16\n",
      "train_loss:  0.5013638138771057  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5377619788050652  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.4166208803653717\n",
      "BATCH:  3  LOSS:  0.6233543157577515\n",
      "BATCH:  5  LOSS:  0.4319581389427185\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  17\n",
      "train_loss:  0.5026017044271741  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5364894382655621  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.5800114274024963\n",
      "BATCH:  3  LOSS:  0.4513579308986664\n",
      "BATCH:  5  LOSS:  0.29624083638191223\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  18\n",
      "train_loss:  0.4950893649033138  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.534366212785244  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.2849172055721283\n",
      "BATCH:  3  LOSS:  0.4117678999900818\n",
      "BATCH:  5  LOSS:  0.8249468803405762\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  19\n",
      "train_loss:  0.48957825558526175  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5334440991282463  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.41736704111099243\n",
      "BATCH:  3  LOSS:  0.8004204034805298\n",
      "BATCH:  5  LOSS:  0.29191315174102783\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  20\n",
      "train_loss:  0.48508461884089876  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5263592302799225  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.5104058980941772\n",
      "BATCH:  3  LOSS:  0.27423718571662903\n",
      "BATCH:  5  LOSS:  0.40941059589385986\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  21\n",
      "train_loss:  0.474791944026947  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5257607661187649  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.5454562306404114\n",
      "BATCH:  3  LOSS:  0.40430375933647156\n",
      "BATCH:  5  LOSS:  0.3315015137195587\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  22\n",
      "train_loss:  0.46834363681929453  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5250452272593975  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.5150748491287231\n",
      "BATCH:  3  LOSS:  0.3515128195285797\n",
      "BATCH:  5  LOSS:  0.2746164798736572\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  23\n",
      "train_loss:  0.46589681080409456  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5354094877839088  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.41997814178466797\n",
      "BATCH:  3  LOSS:  0.530773401260376\n",
      "BATCH:  5  LOSS:  0.7458857297897339\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  24\n",
      "train_loss:  0.4591766340391977  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5230795405805111  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.40059730410575867\n",
      "BATCH:  3  LOSS:  0.2570447623729706\n",
      "BATCH:  5  LOSS:  0.5170391201972961\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  25\n",
      "train_loss:  0.4598114405359541  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5225685797631741  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.3931862711906433\n",
      "BATCH:  3  LOSS:  0.24435685575008392\n",
      "BATCH:  5  LOSS:  0.4978103041648865\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  26\n",
      "train_loss:  0.44155402055808474  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.521944310516119  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.35858869552612305\n",
      "BATCH:  3  LOSS:  0.2774846851825714\n",
      "BATCH:  5  LOSS:  0.39558613300323486\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  27\n",
      "train_loss:  0.44645088485309053  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5189822502434254  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.23492348194122314\n",
      "BATCH:  3  LOSS:  0.6815536618232727\n",
      "BATCH:  5  LOSS:  0.45429858565330505\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  28\n",
      "train_loss:  0.42339323673929485  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5247326046228409  val_accuracy:  83.38955837488174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.44782891869544983\n",
      "BATCH:  3  LOSS:  0.652363121509552\n",
      "BATCH:  5  LOSS:  0.38258805871009827\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  29\n",
      "train_loss:  0.40983037437711445  train_accuracy:  86.10221639275551\n",
      "val_loss:  0.5170016214251518  val_accuracy:  83.4237465262413\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.39156824350357056\n",
      "BATCH:  3  LOSS:  0.37103471159935\n",
      "BATCH:  5  LOSS:  0.6515216827392578\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  30\n",
      "train_loss:  0.4021649679967335  train_accuracy:  86.1344744861126\n",
      "val_loss:  0.5435672551393509  val_accuracy:  82.99346560239792\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.37264037132263184\n",
      "BATCH:  3  LOSS:  0.37765172123908997\n",
      "BATCH:  5  LOSS:  0.4068987965583801\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  31\n",
      "train_loss:  0.3909443212406976  train_accuracy:  86.187106102705\n",
      "val_loss:  0.5328979529440403  val_accuracy:  83.85701942443848\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.35811325907707214\n",
      "BATCH:  3  LOSS:  0.5632290840148926\n",
      "BATCH:  5  LOSS:  0.3419075310230255\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  32\n",
      "train_loss:  0.378548692379679  train_accuracy:  86.32256069779396\n",
      "val_loss:  0.5541397482156754  val_accuracy:  82.75859487056732\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.3262898325920105\n",
      "BATCH:  3  LOSS:  0.5634468793869019\n",
      "BATCH:  5  LOSS:  0.31324058771133423\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  33\n",
      "train_loss:  0.3656518118722098  train_accuracy:  86.7359756231308\n",
      "val_loss:  0.5332599878311157  val_accuracy:  83.25577414035797\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.3554247319698334\n",
      "BATCH:  3  LOSS:  0.18082135915756226\n",
      "BATCH:  5  LOSS:  0.4551016390323639\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  34\n",
      "train_loss:  0.3595595104353769  train_accuracy:  86.56930896639824\n",
      "val_loss:  0.597348652780056  val_accuracy:  81.54726678133011\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.37716299295425415\n",
      "BATCH:  3  LOSS:  0.21849797666072845\n",
      "BATCH:  5  LOSS:  0.5087589025497437\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  35\n",
      "train_loss:  0.34325397653239115  train_accuracy:  87.15798008441925\n",
      "val_loss:  0.5532379187643528  val_accuracy:  82.90218168497086\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.3499819338321686\n",
      "BATCH:  3  LOSS:  0.32048115134239197\n",
      "BATCH:  5  LOSS:  0.33383747935295105\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  36\n",
      "train_loss:  0.3380599979843412  train_accuracy:  87.2076964378357\n",
      "val_loss:  0.5636069737374783  val_accuracy:  83.28854012489319\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.3193616569042206\n",
      "BATCH:  3  LOSS:  0.3932584226131439\n",
      "BATCH:  5  LOSS:  0.27786120772361755\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  37\n",
      "train_loss:  0.3209929849420275  train_accuracy:  87.04822826385498\n",
      "val_loss:  0.5770209282636642  val_accuracy:  82.516093313694\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.3046262264251709\n",
      "BATCH:  3  LOSS:  0.2844097912311554\n",
      "BATCH:  5  LOSS:  0.3107950985431671\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  38\n",
      "train_loss:  0.31007537458624157  train_accuracy:  86.97304874658585\n",
      "val_loss:  0.5853362157940865  val_accuracy:  81.95807331800461\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.2959093451499939\n",
      "BATCH:  3  LOSS:  0.3131554424762726\n",
      "BATCH:  5  LOSS:  0.3020409941673279\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  39\n",
      "train_loss:  0.30071824150426046  train_accuracy:  87.9379997253418\n",
      "val_loss:  0.5968170426785946  val_accuracy:  82.2914167046547\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.276950478553772\n",
      "BATCH:  3  LOSS:  0.3108210563659668\n",
      "BATCH:  5  LOSS:  0.2845410704612732\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  40\n",
      "train_loss:  0.2803464766059603  train_accuracy:  88.32369130849838\n",
      "val_loss:  0.6388103663921356  val_accuracy:  81.99250811338425\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.3099198043346405\n",
      "BATCH:  3  LOSS:  0.2527388036251068\n",
      "BATCH:  5  LOSS:  0.27390256524086\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  41\n",
      "train_loss:  0.2780922544854028  train_accuracy:  87.88205546140671\n",
      "val_loss:  0.639697976410389  val_accuracy:  80.20892888307571\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.28850945830345154\n",
      "BATCH:  3  LOSS:  0.4047255516052246\n",
      "BATCH:  5  LOSS:  0.12468460202217102\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  42\n",
      "train_loss:  0.2683361917734146  train_accuracy:  87.64179122447968\n",
      "val_loss:  0.6346094682812691  val_accuracy:  81.65526252985\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.281962513923645\n",
      "BATCH:  3  LOSS:  0.18398088216781616\n",
      "BATCH:  5  LOSS:  0.28768622875213623\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  43\n",
      "train_loss:  0.2520506680011749  train_accuracy:  88.70565813779831\n",
      "val_loss:  0.6465710625052452  val_accuracy:  81.86695659160614\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.1813875436782837\n",
      "BATCH:  3  LOSS:  0.2670154869556427\n",
      "BATCH:  5  LOSS:  0.2899482548236847\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  44\n",
      "train_loss:  0.23478704584496363  train_accuracy:  89.08213126659393\n",
      "val_loss:  0.6328253783285618  val_accuracy:  80.79148107767105\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.14217588305473328\n",
      "BATCH:  3  LOSS:  0.24322514235973358\n",
      "BATCH:  5  LOSS:  0.11803140491247177\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  45\n",
      "train_loss:  0.22107337521655218  train_accuracy:  89.41877895593643\n",
      "val_loss:  0.6205673292279243  val_accuracy:  82.5731213092804\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.2380441278219223\n",
      "BATCH:  3  LOSS:  0.2813083529472351\n",
      "BATCH:  5  LOSS:  0.11054941266775131\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  46\n",
      "train_loss:  0.20698498508759908  train_accuracy:  89.82195216417313\n",
      "val_loss:  0.665346696972847  val_accuracy:  81.57375109195709\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.23317950963974\n",
      "BATCH:  3  LOSS:  0.18125489354133606\n",
      "BATCH:  5  LOSS:  0.1967368721961975\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  47\n",
      "train_loss:  0.19750022568872996  train_accuracy:  89.7767471075058\n",
      "val_loss:  0.6709918864071369  val_accuracy:  81.96437525749207\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.1257091760635376\n",
      "BATCH:  3  LOSS:  0.08208306133747101\n",
      "BATCH:  5  LOSS:  0.21311919391155243\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  48\n",
      "train_loss:  0.1858498262507575  train_accuracy:  90.13251054286957\n",
      "val_loss:  0.6883992627263069  val_accuracy:  81.34449923038483\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.060794539749622345\n",
      "BATCH:  3  LOSS:  0.1735224574804306\n",
      "BATCH:  5  LOSS:  0.21615298092365265\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  49\n",
      "train_loss:  0.17292565000908716  train_accuracy:  90.6209664940834\n",
      "val_loss:  0.7041687369346619  val_accuracy:  81.32935321331024\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.2190302163362503\n",
      "BATCH:  3  LOSS:  0.11548762768507004\n",
      "BATCH:  5  LOSS:  0.18945272266864777\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  50\n",
      "train_loss:  0.16935937532356807  train_accuracy:  90.94280058145523\n",
      "val_loss:  0.6486335471272469  val_accuracy:  82.5586565732956\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.188888281583786\n",
      "BATCH:  3  LOSS:  0.2052735984325409\n",
      "BATCH:  5  LOSS:  0.1475393921136856\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  51\n",
      "train_loss:  0.1576257592865399  train_accuracy:  90.96841526031494\n",
      "val_loss:  0.6662526354193687  val_accuracy:  82.27953350543976\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.1903524398803711\n",
      "BATCH:  3  LOSS:  0.1306878924369812\n",
      "BATCH:  5  LOSS:  0.04608913138508797\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  52\n",
      "train_loss:  0.14459184716854775  train_accuracy:  90.93846452236176\n",
      "val_loss:  0.7338075563311577  val_accuracy:  80.58044242858887\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.1202118843793869\n",
      "BATCH:  3  LOSS:  0.12684202194213867\n",
      "BATCH:  5  LOSS:  0.09919914603233337\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  53\n",
      "train_loss:  0.1298028374356883  train_accuracy:  91.57301336526871\n",
      "val_loss:  0.6910143345594406  val_accuracy:  82.88704347610474\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.08239255100488663\n",
      "BATCH:  3  LOSS:  0.036298636347055435\n",
      "BATCH:  5  LOSS:  0.1972157508134842\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  54\n",
      "train_loss:  0.1261048684162753  train_accuracy:  92.10364586114883\n",
      "val_loss:  0.7286148369312286  val_accuracy:  81.02327942848206\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.11020949482917786\n",
      "BATCH:  3  LOSS:  0.03346111625432968\n",
      "BATCH:  5  LOSS:  0.11184825003147125\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  55\n",
      "train_loss:  0.11579066621405738  train_accuracy:  92.02755099534988\n",
      "val_loss:  0.7456273660063744  val_accuracy:  81.17942821979523\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.10835734009742737\n",
      "BATCH:  3  LOSS:  0.1559802144765854\n",
      "BATCH:  5  LOSS:  0.13494598865509033\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  56\n",
      "train_loss:  0.10831483772822789  train_accuracy:  92.46369379758835\n",
      "val_loss:  0.7760947868227959  val_accuracy:  78.49196791648865\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.14941324293613434\n",
      "BATCH:  3  LOSS:  0.20365671813488007\n",
      "BATCH:  5  LOSS:  0.126220241189003\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  57\n",
      "train_loss:  0.12400852463075093  train_accuracy:  91.63613647222519\n",
      "val_loss:  0.8175309672951698  val_accuracy:  76.61142832040787\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.13555985689163208\n",
      "BATCH:  3  LOSS:  0.16207723319530487\n",
      "BATCH:  5  LOSS:  0.09916513413190842\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  58\n",
      "train_loss:  0.1441170328429767  train_accuracy:  91.02005922794342\n",
      "val_loss:  0.745242714881897  val_accuracy:  81.29868686199188\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.07363547384738922\n",
      "BATCH:  3  LOSS:  0.19646191596984863\n",
      "BATCH:  5  LOSS:  0.12795177102088928\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  59\n",
      "train_loss:  0.12850507561649596  train_accuracy:  91.73910790681839\n",
      "val_loss:  0.7475084438920021  val_accuracy:  81.38209140300751\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.03253503888845444\n",
      "BATCH:  3  LOSS:  0.16994927823543549\n",
      "BATCH:  5  LOSS:  0.07864801585674286\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  60\n",
      "train_loss:  0.11335065748010363  train_accuracy:  91.93049734830856\n",
      "val_loss:  0.8074094206094742  val_accuracy:  80.49186551570892\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.09995027631521225\n",
      "BATCH:  3  LOSS:  0.0801965519785881\n",
      "BATCH:  5  LOSS:  0.1536015123128891\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  61\n",
      "train_loss:  0.100725740726505  train_accuracy:  92.62930524349213\n",
      "val_loss:  0.7349411584436893  val_accuracy:  82.57208561897278\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.05160592496395111\n",
      "BATCH:  3  LOSS:  0.09128926694393158\n",
      "BATCH:  5  LOSS:  0.10867577791213989\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  62\n",
      "train_loss:  0.08469212374516896  train_accuracy:  92.85908776521683\n",
      "val_loss:  0.7673791609704494  val_accuracy:  82.59539663791656\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.07731302082538605\n",
      "BATCH:  3  LOSS:  0.052098967134952545\n",
      "BATCH:  5  LOSS:  0.07319840788841248\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  63\n",
      "train_loss:  0.07833724947912353  train_accuracy:  92.75700896978378\n",
      "val_loss:  0.759268008172512  val_accuracy:  81.07221531867981\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.06021340563893318\n",
      "BATCH:  3  LOSS:  0.11183688044548035\n",
      "BATCH:  5  LOSS:  0.0931112989783287\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  64\n",
      "train_loss:  0.07254046547625746  train_accuracy:  93.63412761688232\n",
      "val_loss:  0.7728617042303085  val_accuracy:  82.26285183429718\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.08449852466583252\n",
      "BATCH:  3  LOSS:  0.02853735350072384\n",
      "BATCH:  5  LOSS:  0.10712379217147827\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  65\n",
      "train_loss:  0.06787670483546597  train_accuracy:  93.42617076635361\n",
      "val_loss:  0.7888782024383545  val_accuracy:  81.35366213321686\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.03797207400202751\n",
      "BATCH:  3  LOSS:  0.05748241767287254\n",
      "BATCH:  5  LOSS:  0.019748711958527565\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  66\n",
      "train_loss:  0.05899236058550222  train_accuracy:  94.15870612859726\n",
      "val_loss:  0.8100724890828133  val_accuracy:  82.36491012573242\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.0937725380063057\n",
      "BATCH:  3  LOSS:  0.06062297150492668\n",
      "BATCH:  5  LOSS:  0.0442001037299633\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  67\n",
      "train_loss:  0.056339837344629426  train_accuracy:  93.67206108570099\n",
      "val_loss:  0.8017284795641899  val_accuracy:  81.41118514537811\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.018855471163988113\n",
      "BATCH:  3  LOSS:  0.0647510290145874\n",
      "BATCH:  5  LOSS:  0.05074024200439453\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  68\n",
      "train_loss:  0.05049068959695952  train_accuracy:  94.11925929784775\n",
      "val_loss:  0.8220569267868996  val_accuracy:  81.06334328651428\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.06352920085191727\n",
      "BATCH:  3  LOSS:  0.07557373493909836\n",
      "BATCH:  5  LOSS:  0.05082404613494873\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  69\n",
      "train_loss:  0.047563298738428524  train_accuracy:  94.39637106657028\n",
      "val_loss:  0.8192414566874504  val_accuracy:  81.01397168636322\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.07024730741977692\n",
      "BATCH:  3  LOSS:  0.03993767872452736\n",
      "BATCH:  5  LOSS:  0.0506509393453598\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  70\n",
      "train_loss:  0.04362150188535452  train_accuracy:  94.52027094364166\n",
      "val_loss:  0.8179236799478531  val_accuracy:  82.14468252658844\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.04610221087932587\n",
      "BATCH:  3  LOSS:  0.045857466757297516\n",
      "BATCH:  5  LOSS:  0.027373338118195534\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  71\n",
      "train_loss:  0.04283079159046922  train_accuracy:  94.3814218044281\n",
      "val_loss:  0.8446702137589455  val_accuracy:  81.67800760269165\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.05399293452501297\n",
      "BATCH:  3  LOSS:  0.06414085626602173\n",
      "BATCH:  5  LOSS:  0.01511023472994566\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  72\n",
      "train_loss:  0.04010940782193627  train_accuracy:  94.53746050596237\n",
      "val_loss:  0.8418278843164444  val_accuracy:  81.80877637863159\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.040569886565208435\n",
      "BATCH:  3  LOSS:  0.04874581843614578\n",
      "BATCH:  5  LOSS:  0.013160950504243374\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  73\n",
      "train_loss:  0.039040850076292245  train_accuracy:  94.56126999855042\n",
      "val_loss:  0.8392798155546188  val_accuracy:  82.15742087364197\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.04356614127755165\n",
      "BATCH:  3  LOSS:  0.03689373657107353\n",
      "BATCH:  5  LOSS:  0.06412100046873093\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  74\n",
      "train_loss:  0.04021292472524302  train_accuracy:  94.54520243406296\n",
      "val_loss:  0.8688987120985985  val_accuracy:  81.2093894481659\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.05190825089812279\n",
      "BATCH:  3  LOSS:  0.04580762982368469\n",
      "BATCH:  5  LOSS:  0.01659514755010605\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  75\n",
      "train_loss:  0.040039589894669395  train_accuracy:  94.69924485683441\n",
      "val_loss:  0.8494241237640381  val_accuracy:  80.64656674861908\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.028775347396731377\n",
      "BATCH:  3  LOSS:  0.03585948050022125\n",
      "BATCH:  5  LOSS:  0.04485839232802391\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  76\n",
      "train_loss:  0.040039366643343656  train_accuracy:  94.4996468424797\n",
      "val_loss:  0.889748752117157  val_accuracy:  80.00542640686035\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.015317211858928204\n",
      "BATCH:  3  LOSS:  0.06054464355111122\n",
      "BATCH:  5  LOSS:  0.029523232951760292\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  77\n",
      "train_loss:  0.03834036644548178  train_accuracy:  94.71220779418945\n",
      "val_loss:  0.8594264760613441  val_accuracy:  81.56579291820526\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.02580425702035427\n",
      "BATCH:  3  LOSS:  0.03291000798344612\n",
      "BATCH:  5  LOSS:  0.015089195221662521\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  78\n",
      "train_loss:  0.04189700127712318  train_accuracy:  94.38907665014267\n",
      "val_loss:  0.8700830191373825  val_accuracy:  80.88890850543976\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.04641592502593994\n",
      "BATCH:  3  LOSS:  0.011245975270867348\n",
      "BATCH:  5  LOSS:  0.04037560895085335\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  79\n",
      "train_loss:  0.046802357637456486  train_accuracy:  94.16293919086456\n",
      "val_loss:  0.8879148960113525  val_accuracy:  81.2225878238678\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.03914851322770119\n",
      "BATCH:  3  LOSS:  0.049879010766744614\n",
      "BATCH:  5  LOSS:  0.0743560940027237\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  80\n",
      "train_loss:  0.05861134534435613  train_accuracy:  94.00539553165436\n",
      "val_loss:  0.9230677336454391  val_accuracy:  80.00545239448547\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.06431116908788681\n",
      "BATCH:  3  LOSS:  0.06710602343082428\n",
      "BATCH:  5  LOSS:  0.06999913603067398\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  81\n",
      "train_loss:  0.07605932573122638  train_accuracy:  93.25781762599945\n",
      "val_loss:  0.9073543176054955  val_accuracy:  81.71403288841248\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.06604883074760437\n",
      "BATCH:  3  LOSS:  0.04930165410041809\n",
      "BATCH:  5  LOSS:  0.1166645959019661\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  82\n",
      "train_loss:  0.08770916504519326  train_accuracy:  92.663006067276\n",
      "val_loss:  0.8845509737730026  val_accuracy:  83.25074422359467\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.08918870240449905\n",
      "BATCH:  3  LOSS:  0.1819031983613968\n",
      "BATCH:  5  LOSS:  0.15255731344223022\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  83\n",
      "train_loss:  0.1110285616346768  train_accuracy:  92.09716123342514\n",
      "val_loss:  0.7841528728604317  val_accuracy:  82.80024826526642\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.07989294081926346\n",
      "BATCH:  3  LOSS:  0.13810370862483978\n",
      "BATCH:  5  LOSS:  0.08702173829078674\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  84\n",
      "train_loss:  0.09568251935499054  train_accuracy:  93.02255427837372\n",
      "val_loss:  0.9012423455715179  val_accuracy:  80.28149163722992\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.060967911034822464\n",
      "BATCH:  3  LOSS:  0.012773617170751095\n",
      "BATCH:  5  LOSS:  0.08081091940402985\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  85\n",
      "train_loss:  0.0724281534286482  train_accuracy:  92.57201397418976\n",
      "val_loss:  0.8484292253851891  val_accuracy:  81.88541913032532\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.06114035099744797\n",
      "BATCH:  3  LOSS:  0.07435226440429688\n",
      "BATCH:  5  LOSS:  0.10083571076393127\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  86\n",
      "train_loss:  0.06022138547684465  train_accuracy:  93.707679271698\n",
      "val_loss:  0.7846601828932762  val_accuracy:  82.63214087486267\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.043946485966444016\n",
      "BATCH:  3  LOSS:  0.016985196620225906\n",
      "BATCH:  5  LOSS:  0.06835676729679108\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  87\n",
      "train_loss:  0.047961990748132975  train_accuracy:  93.96668094396591\n",
      "val_loss:  0.8238152265548706  val_accuracy:  82.20204150676727\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.03359450772404671\n",
      "BATCH:  3  LOSS:  0.04149055853486061\n",
      "BATCH:  5  LOSS:  0.05581410974264145\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  88\n",
      "train_loss:  0.03904309882117169  train_accuracy:  94.48510807752609\n",
      "val_loss:  0.8412132039666176  val_accuracy:  82.59727954864502\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.04623958095908165\n",
      "BATCH:  3  LOSS:  0.010444492101669312\n",
      "BATCH:  5  LOSS:  0.03161441162228584\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  89\n",
      "train_loss:  0.03133593233568328  train_accuracy:  94.7398117184639\n",
      "val_loss:  0.8600208386778831  val_accuracy:  82.88546311855316\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.030245210975408554\n",
      "BATCH:  3  LOSS:  0.044306039810180664\n",
      "BATCH:  5  LOSS:  0.035872045904397964\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  90\n",
      "train_loss:  0.027419337736708776  train_accuracy:  94.89732784032822\n",
      "val_loss:  0.8705848231911659  val_accuracy:  82.43077409267426\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.03275923430919647\n",
      "BATCH:  3  LOSS:  0.04130574315786362\n",
      "BATCH:  5  LOSS:  0.02121085114777088\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  91\n",
      "train_loss:  0.02516762193824564  train_accuracy:  94.85710418224335\n",
      "val_loss:  0.8834830597043037  val_accuracy:  82.18063163757324\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.026322996243834496\n",
      "BATCH:  3  LOSS:  0.007732970640063286\n",
      "BATCH:  5  LOSS:  0.019810296595096588\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  92\n",
      "train_loss:  0.024627138461385454  train_accuracy:  94.89609622955322\n",
      "val_loss:  0.8918284028768539  val_accuracy:  82.18612623214722\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.024350082501769066\n",
      "BATCH:  3  LOSS:  0.020095255225896835\n",
      "BATCH:  5  LOSS:  0.024905599653720856\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  93\n",
      "train_loss:  0.023817280839596475  train_accuracy:  94.86506980657578\n",
      "val_loss:  0.9120754897594452  val_accuracy:  82.3971244096756\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.02621038630604744\n",
      "BATCH:  3  LOSS:  0.023662207648158073\n",
      "BATCH:  5  LOSS:  0.038366589695215225\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  94\n",
      "train_loss:  0.024688166699239185  train_accuracy:  94.96211361885071\n",
      "val_loss:  0.8763056993484497  val_accuracy:  82.23288941383362\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.018820742145180702\n",
      "BATCH:  3  LOSS:  0.007543385960161686\n",
      "BATCH:  5  LOSS:  0.04466385394334793\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  95\n",
      "train_loss:  0.02422103565186262  train_accuracy:  94.8786889910698\n",
      "val_loss:  0.8731209859251976  val_accuracy:  82.03050577640533\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.00994853861629963\n",
      "BATCH:  3  LOSS:  0.037754081189632416\n",
      "BATCH:  5  LOSS:  0.031102802604436874\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  96\n",
      "train_loss:  0.025615442278129712  train_accuracy:  94.91918236017227\n",
      "val_loss:  0.8938343450427055  val_accuracy:  82.16816711425781\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.01985917054116726\n",
      "BATCH:  3  LOSS:  0.028012540191411972\n",
      "BATCH:  5  LOSS:  0.021271247416734695\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  97\n",
      "train_loss:  0.02435261902532407  train_accuracy:  94.96211361885071\n",
      "val_loss:  0.89795833081007  val_accuracy:  81.79422700405121\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.0076014031656086445\n",
      "BATCH:  3  LOSS:  0.03674883022904396\n",
      "BATCH:  5  LOSS:  0.026660887524485588\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  98\n",
      "train_loss:  0.024035364722034762  train_accuracy:  94.96211361885071\n",
      "val_loss:  0.8949580192565918  val_accuracy:  80.77814471721649\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.028166629374027252\n",
      "BATCH:  3  LOSS:  0.025440359488129616\n",
      "BATCH:  5  LOSS:  0.038358092308044434\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  99\n",
      "train_loss:  0.02512217060263668  train_accuracy:  94.92763090133667\n",
      "val_loss:  0.8962530121207237  val_accuracy:  81.67907726764679\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.022858401760458946\n",
      "BATCH:  3  LOSS:  0.026213234290480614\n",
      "BATCH:  5  LOSS:  0.035828422755002975\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  100\n",
      "train_loss:  0.023550849674003466  train_accuracy:  94.99241667985916\n",
      "val_loss:  0.8973590135574341  val_accuracy:  82.19313669204712\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.025793608278036118\n",
      "BATCH:  3  LOSS:  0.03491903096437454\n",
      "BATCH:  5  LOSS:  0.017668351531028748\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  101\n",
      "train_loss:  0.023737439220505103  train_accuracy:  94.96211361885071\n",
      "val_loss:  0.8918997943401337  val_accuracy:  81.07470154762268\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.018589572980999947\n",
      "BATCH:  3  LOSS:  0.024227041751146317\n",
      "BATCH:  5  LOSS:  0.030681706964969635\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  102\n",
      "train_loss:  0.02388088564787592  train_accuracy:  94.96211361885071\n",
      "val_loss:  0.8945706412196159  val_accuracy:  80.87090706825256\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.03449643775820732\n",
      "BATCH:  3  LOSS:  0.021165218204259872\n",
      "BATCH:  5  LOSS:  0.02051432803273201\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  103\n",
      "train_loss:  0.023221775889396667  train_accuracy:  94.99241667985916\n",
      "val_loss:  0.8992386907339096  val_accuracy:  81.98277997970581\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.03513912484049797\n",
      "BATCH:  3  LOSS:  0.02831565961241722\n",
      "BATCH:  5  LOSS:  0.019140038639307022\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  104\n",
      "train_loss:  0.022815773662711893  train_accuracy:  95.0162261724472\n",
      "val_loss:  0.9060235545039177  val_accuracy:  82.32437515258789\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.022185496985912323\n",
      "BATCH:  3  LOSS:  0.026475444436073303\n",
      "BATCH:  5  LOSS:  0.029443275183439255\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  105\n",
      "train_loss:  0.0233114866672882  train_accuracy:  94.98396813869476\n",
      "val_loss:  0.8942387327551842  val_accuracy:  81.19816267490387\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.017921993508934975\n",
      "BATCH:  3  LOSS:  0.03342718631029129\n",
      "BATCH:  5  LOSS:  0.027255820110440254\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  106\n",
      "train_loss:  0.0238530414977244  train_accuracy:  94.98592311143875\n",
      "val_loss:  0.902961254119873  val_accuracy:  81.07944059371948\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.026085037738084793\n",
      "BATCH:  3  LOSS:  0.041493505239486694\n",
      "BATCH:  5  LOSS:  0.027286604046821594\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  107\n",
      "train_loss:  0.024447191772716387  train_accuracy:  94.96413743495941\n",
      "val_loss:  0.9131061658263206  val_accuracy:  80.76548898220062\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.026820315048098564\n",
      "BATCH:  3  LOSS:  0.009225714951753616\n",
      "BATCH:  5  LOSS:  0.038711607456207275\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  108\n",
      "train_loss:  0.024718669642295157  train_accuracy:  94.94230151176453\n",
      "val_loss:  0.9230375662446022  val_accuracy:  79.63973969221115\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.02479076199233532\n",
      "BATCH:  3  LOSS:  0.033470094203948975\n",
      "BATCH:  5  LOSS:  0.02166166715323925\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  109\n",
      "train_loss:  0.025817940809897015  train_accuracy:  94.91568547487259\n",
      "val_loss:  0.9059871211647987  val_accuracy:  80.92445600032806\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.026861678808927536\n",
      "BATCH:  3  LOSS:  0.011202110908925533\n",
      "BATCH:  5  LOSS:  0.047512203454971313\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  110\n",
      "train_loss:  0.031351616739162376  train_accuracy:  94.73714971542358\n",
      "val_loss:  0.9476832523941994  val_accuracy:  79.72849500179291\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.04267207533121109\n",
      "BATCH:  3  LOSS:  0.06553973257541656\n",
      "BATCH:  5  LOSS:  0.07387170195579529\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  111\n",
      "train_loss:  0.05028093859021153  train_accuracy:  94.03785985708237\n",
      "val_loss:  0.9195600897073746  val_accuracy:  82.34403997659683\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.03786388039588928\n",
      "BATCH:  3  LOSS:  0.12871471047401428\n",
      "BATCH:  5  LOSS:  0.016695089638233185\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  112\n",
      "train_loss:  0.08346664586237498  train_accuracy:  92.44938969612122\n",
      "val_loss:  0.9693900942802429  val_accuracy:  80.50495111942291\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.07503459602594376\n",
      "BATCH:  3  LOSS:  0.027706313878297806\n",
      "BATCH:  5  LOSS:  0.12798640131950378\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  113\n",
      "train_loss:  0.09112171136907168  train_accuracy:  92.22994548082352\n",
      "val_loss:  0.912481851875782  val_accuracy:  78.66693729162216\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.0747741162776947\n",
      "BATCH:  3  LOSS:  0.12291152775287628\n",
      "BATCH:  5  LOSS:  0.08776316046714783\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  114\n",
      "train_loss:  0.08738767674991063  train_accuracy:  92.72327625751495\n",
      "val_loss:  0.8843169212341309  val_accuracy:  81.69482588768005\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.029507791623473167\n",
      "BATCH:  3  LOSS:  0.09918681532144547\n",
      "BATCH:  5  LOSS:  0.10037615150213242\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  115\n",
      "train_loss:  0.07172330282628536  train_accuracy:  93.3832219839096\n",
      "val_loss:  0.8673452138900757  val_accuracy:  83.73070526123047\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.05940309166908264\n",
      "BATCH:  3  LOSS:  0.05242147669196129\n",
      "BATCH:  5  LOSS:  0.031025461852550507\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  116\n",
      "train_loss:  0.04930412928972926  train_accuracy:  93.98336094617844\n",
      "val_loss:  0.8931277692317963  val_accuracy:  82.49919784069061\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.053676802664995193\n",
      "BATCH:  3  LOSS:  0.06542913615703583\n",
      "BATCH:  5  LOSS:  0.02880186215043068\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  117\n",
      "train_loss:  0.03857908770442009  train_accuracy:  94.27876389026642\n",
      "val_loss:  0.9506876692175865  val_accuracy:  80.3011863231659\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.02606273628771305\n",
      "BATCH:  3  LOSS:  0.01998443342745304\n",
      "BATCH:  5  LOSS:  0.02759794518351555\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  118\n",
      "train_loss:  0.03413918281772307  train_accuracy:  94.42332708835602\n",
      "val_loss:  0.8936314210295677  val_accuracy:  82.13910162448883\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.024682627990841866\n",
      "BATCH:  3  LOSS:  0.024555839598178864\n",
      "BATCH:  5  LOSS:  0.036241818219423294\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  119\n",
      "train_loss:  0.02665133055831705  train_accuracy:  94.79257762432098\n",
      "val_loss:  0.9201951697468758  val_accuracy:  83.46248352527618\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.020724771544337273\n",
      "BATCH:  3  LOSS:  0.027504276484251022\n",
      "BATCH:  5  LOSS:  0.03580128774046898\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  120\n",
      "train_loss:  0.0226717989093491  train_accuracy:  94.99241667985916\n",
      "val_loss:  0.896840788424015  val_accuracy:  81.7545690536499\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.014586551114916801\n",
      "BATCH:  3  LOSS:  0.025080908089876175\n",
      "BATCH:  5  LOSS:  0.01783563755452633\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  121\n",
      "train_loss:  0.018967179182384695  train_accuracy:  94.96211361885071\n",
      "val_loss:  0.9231240078806877  val_accuracy:  82.57072043418884\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.013582897372543812\n",
      "BATCH:  3  LOSS:  0.01426510326564312\n",
      "BATCH:  5  LOSS:  0.021413354203104973\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  122\n",
      "train_loss:  0.01807677193677851  train_accuracy:  95.0495594739914\n",
      "val_loss:  0.9212056919932365  val_accuracy:  82.03546524047852\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.011071248911321163\n",
      "BATCH:  3  LOSS:  0.02223164215683937\n",
      "BATCH:  5  LOSS:  0.027896689251065254\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  123\n",
      "train_loss:  0.017386298959276507  train_accuracy:  95.0162261724472\n",
      "val_loss:  0.9220545738935471  val_accuracy:  82.24935710430145\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.015055752359330654\n",
      "BATCH:  3  LOSS:  0.019815314561128616\n",
      "BATCH:  5  LOSS:  0.018018461763858795\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  124\n",
      "train_loss:  0.017010319911475693  train_accuracy:  95.05468767881393\n",
      "val_loss:  0.9137259796261787  val_accuracy:  82.49383819103241\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.006456479895859957\n",
      "BATCH:  3  LOSS:  0.0258258655667305\n",
      "BATCH:  5  LOSS:  0.016802169382572174\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  125\n",
      "train_loss:  0.017590999802840606  train_accuracy:  95.05468767881393\n",
      "val_loss:  0.9135508388280869  val_accuracy:  82.03579342365265\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.019081121310591698\n",
      "BATCH:  3  LOSS:  0.022746602073311806\n",
      "BATCH:  5  LOSS:  0.022011246532201767\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  126\n",
      "train_loss:  0.017881042190960476  train_accuracy:  95.08802098035812\n",
      "val_loss:  0.9074751287698746  val_accuracy:  82.06250405311584\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.02184659242630005\n",
      "BATCH:  3  LOSS:  0.015120558440685272\n",
      "BATCH:  5  LOSS:  0.02671503834426403\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  127\n",
      "train_loss:  0.018079860734620264  train_accuracy:  95.0495594739914\n",
      "val_loss:  0.9044088423252106  val_accuracy:  81.75515353679657\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.018525397405028343\n",
      "BATCH:  3  LOSS:  0.01658429391682148\n",
      "BATCH:  5  LOSS:  0.022126683965325356\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  128\n",
      "train_loss:  0.018559213062482222  train_accuracy:  95.08802098035812\n",
      "val_loss:  0.9010492712259293  val_accuracy:  81.50737512111664\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.02139119803905487\n",
      "BATCH:  3  LOSS:  0.007387644145637751\n",
      "BATCH:  5  LOSS:  0.016067789867520332\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  129\n",
      "train_loss:  0.018819124903529882  train_accuracy:  95.0162261724472\n",
      "val_loss:  0.913386382162571  val_accuracy:  82.10290831327438\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.014900746755301952\n",
      "BATCH:  3  LOSS:  0.019625743851065636\n",
      "BATCH:  5  LOSS:  0.016090676188468933\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  130\n",
      "train_loss:  0.018689347497586693  train_accuracy:  95.08802098035812\n",
      "val_loss:  0.9030716791749  val_accuracy:  81.0519015789032\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.022477615624666214\n",
      "BATCH:  3  LOSS:  0.015900030732154846\n",
      "BATCH:  5  LOSS:  0.01910010538995266\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  131\n",
      "train_loss:  0.01913297868200711  train_accuracy:  95.08802098035812\n",
      "val_loss:  0.9084518328309059  val_accuracy:  81.79024559259415\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.006617289502173662\n",
      "BATCH:  3  LOSS:  0.02184731885790825\n",
      "BATCH:  5  LOSS:  0.028665799647569656\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  132\n",
      "train_loss:  0.01878869380535824  train_accuracy:  95.03087818622589\n",
      "val_loss:  0.9072293266654015  val_accuracy:  81.55081933736801\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.01543287094682455\n",
      "BATCH:  3  LOSS:  0.023123985156416893\n",
      "BATCH:  5  LOSS:  0.007644246332347393\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  133\n",
      "train_loss:  0.019050987969551767  train_accuracy:  95.08802098035812\n",
      "val_loss:  0.910237044095993  val_accuracy:  80.73682218790054\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.014476364478468895\n",
      "BATCH:  3  LOSS:  0.018534881994128227\n",
      "BATCH:  5  LOSS:  0.022767826914787292\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  134\n",
      "train_loss:  0.01925226633570024  train_accuracy:  95.05468767881393\n",
      "val_loss:  0.906616285443306  val_accuracy:  80.52247530221939\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.026923587545752525\n",
      "BATCH:  3  LOSS:  0.016261164098978043\n",
      "BATCH:  5  LOSS:  0.023068951442837715\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  135\n",
      "train_loss:  0.02068296992885215  train_accuracy:  95.05468767881393\n",
      "val_loss:  0.9177483692765236  val_accuracy:  81.73662561178207\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.021327683702111244\n",
      "BATCH:  3  LOSS:  0.008749390952289104\n",
      "BATCH:  5  LOSS:  0.016589980572462082\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  136\n",
      "train_loss:  0.020541251370949403  train_accuracy:  95.05468767881393\n",
      "val_loss:  0.9162353351712227  val_accuracy:  81.71587175130844\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.019107801839709282\n",
      "BATCH:  3  LOSS:  0.026885099709033966\n",
      "BATCH:  5  LOSS:  0.02878357097506523\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  137\n",
      "train_loss:  0.019285264957164015  train_accuracy:  95.03390842676163\n",
      "val_loss:  0.9230112433433533  val_accuracy:  81.61471557617188\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.01943287067115307\n",
      "BATCH:  3  LOSS:  0.02476891689002514\n",
      "BATCH:  5  LOSS:  0.01704065315425396\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  138\n",
      "train_loss:  0.01859143575919526  train_accuracy:  95.06421148777008\n",
      "val_loss:  0.9178224131464958  val_accuracy:  80.78567320108414\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.018626190721988678\n",
      "BATCH:  3  LOSS:  0.006495887413620949\n",
      "BATCH:  5  LOSS:  0.02329682931303978\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  139\n",
      "train_loss:  0.01854952158672469  train_accuracy:  95.08802098035812\n",
      "val_loss:  0.9224943667650223  val_accuracy:  80.34405571222305\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.01849311776459217\n",
      "BATCH:  3  LOSS:  0.01891869120299816\n",
      "BATCH:  5  LOSS:  0.013134624809026718\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  140\n",
      "train_loss:  0.01845532369666866  train_accuracy:  95.08802098035812\n",
      "val_loss:  0.9367381259799004  val_accuracy:  81.5899561047554\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.0059473770670592785\n",
      "BATCH:  3  LOSS:  0.016109541058540344\n",
      "BATCH:  5  LOSS:  0.029397733509540558\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  141\n",
      "train_loss:  0.01878524591614093  train_accuracy:  95.05468767881393\n",
      "val_loss:  0.9273704364895821  val_accuracy:  80.12369960546494\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.021604349836707115\n",
      "BATCH:  3  LOSS:  0.01400721911340952\n",
      "BATCH:  5  LOSS:  0.022944655269384384\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  142\n",
      "train_loss:  0.0191455160134605  train_accuracy:  95.05468767881393\n",
      "val_loss:  0.9305315315723419  val_accuracy:  80.54175347089767\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.02647031471133232\n",
      "BATCH:  3  LOSS:  0.0068280636332929134\n",
      "BATCH:  5  LOSS:  0.015353416092693806\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  143\n",
      "train_loss:  0.018849158460008248  train_accuracy:  95.08802098035812\n",
      "val_loss:  0.9403392672538757  val_accuracy:  80.12251740694046\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.01866825297474861\n",
      "BATCH:  3  LOSS:  0.027012163773179054\n",
      "BATCH:  5  LOSS:  0.023744886741042137\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  144\n",
      "train_loss:  0.018767034634947777  train_accuracy:  95.08802098035812\n",
      "val_loss:  0.9246115311980247  val_accuracy:  80.22572785615921\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.007643039338290691\n",
      "BATCH:  3  LOSS:  0.015191140584647655\n",
      "BATCH:  5  LOSS:  0.02069832570850849\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  145\n",
      "train_loss:  0.018883037513920238  train_accuracy:  95.00057512521744\n",
      "val_loss:  0.9320155829191208  val_accuracy:  80.82064145803452\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.01654590293765068\n",
      "BATCH:  3  LOSS:  0.021377351135015488\n",
      "BATCH:  5  LOSS:  0.014753864146769047\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  146\n",
      "train_loss:  0.01837592465536935  train_accuracy:  95.05468767881393\n",
      "val_loss:  0.9336400628089905  val_accuracy:  80.86706763505936\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.01741975173354149\n",
      "BATCH:  3  LOSS:  0.017529498785734177\n",
      "BATCH:  5  LOSS:  0.023172378540039062\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  147\n",
      "train_loss:  0.01880312870655741  train_accuracy:  95.08802098035812\n",
      "val_loss:  0.9436228647828102  val_accuracy:  80.00864678621292\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.01304913405328989\n",
      "BATCH:  3  LOSS:  0.023060638457536697\n",
      "BATCH:  5  LOSS:  0.016992369666695595\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  148\n",
      "train_loss:  0.019390623484339033  train_accuracy:  95.08802098035812\n",
      "val_loss:  0.9471902400255203  val_accuracy:  79.64650636911392\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      "BATCH:  1  LOSS:  0.015412881970405579\n",
      "BATCH:  3  LOSS:  0.023973189294338226\n",
      "BATCH:  5  LOSS:  0.016579562798142433\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n",
      " EPOCH  149\n",
      "train_loss:  0.01990683563053608  train_accuracy:  95.08802098035812\n",
      "val_loss:  0.9553065523505211  val_accuracy:  79.57908433675766\n",
      "\n",
      " ---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 150\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "\n",
    "for i in range(NUM_EPOCHS): #chnage rahe to (N, 2*N) if u r running same thing again to incree no. of epochs\n",
    "#     train_loss, train_accuracy = train(model, initial_train_dataloader, optimizer, loss_fn, i)\n",
    "\n",
    "    #UNCOMMENT\n",
    "    train_loss, train_accuracy = train(model, train_dataloader, optimizer, loss_fn, i)\n",
    "    \n",
    "#     print(\"_______________________________________***************_______________________________\")\n",
    "    val_loss, val_accuracy = evaluate(model, val_dataloader,loss_fn)\n",
    "\n",
    "\n",
    "    print(\"\\n ---------------------------------------------------------------------\\n\")\n",
    "    print(\" EPOCH \", i)\n",
    "    print(\"train_loss: \", train_loss, \" train_accuracy: \", train_accuracy)\n",
    "    \n",
    "    #UNCOMMENT\n",
    "    \n",
    "#     print(\"train_loss: \", avg_train_loss, \" train_accuracy: \", train_accuracy)\n",
    "    print(\"val_loss: \", val_loss, \" val_accuracy: \", val_accuracy)\n",
    "    print(\"\\n ---------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    \n",
    "    writer.add_scalars('LOSS', { 'Train' : train_loss,\n",
    "                                'Val' : val_loss\n",
    "                                } , i)\n",
    "    \n",
    "    writer.add_scalars('ACCURACY', { 'Train': train_accuracy,\n",
    "                                    'val': val_accuracy\n",
    "                                    }, i)\n",
    "    \n",
    "    \n",
    "    #UNCOMMENT\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'RNN_grammer_trial_3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "41a01828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "efc24648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crct_class 183\n",
      "incrct_class 3\n",
      "other_class 186\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "crct_class = 0\n",
    "incrct_class = 0\n",
    "other_class = 0\n",
    "for dat in train_dataloader:\n",
    "    X = dat.tokens\n",
    "    Y = dat.labels\n",
    "#     print(\"here: \",len(X))\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "    #move to GPU\n",
    "        x,y = X[i].to(device), Y[i].to(device)\n",
    "\n",
    "\n",
    "        # Compute prediction error\n",
    "\n",
    "        x = x.unsqueeze(0)\n",
    "        y = y.unsqueeze(0)\n",
    "\n",
    "#         print(x.size(),\": x\")\n",
    "#         print(\"y: \", y.size())\n",
    "\n",
    "        check_pred,_ = model(x)\n",
    "#         print(\"check_pred\",check_pred.size())\n",
    "        check_pred = torch.argmax(check_pred, dim = 1)\n",
    "    #     print(check_pred)\n",
    "\n",
    "    #     print(y.size())\n",
    "    #     break\n",
    "\n",
    "        for i in range(len(y[0])):\n",
    "            if y[0][i] not in [1,0,2]:\n",
    "                other_class += 1\n",
    "                if y[0][i] == check_pred[0][i] :\n",
    "                    crct_class += 1\n",
    "\n",
    "                else:\n",
    "                    incrct_class += 1\n",
    "\n",
    "print(\"crct_class\", crct_class)\n",
    "print(\"incrct_class\", incrct_class)\n",
    "print(\"other_class\", other_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "3a648a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mr',\n",
       " 'charnley',\n",
       " 'said',\n",
       " 'either',\n",
       " 'the',\n",
       " 'council',\n",
       " 'was',\n",
       " 'also',\n",
       " 'considering',\n",
       " 'up',\n",
       " 'whether',\n",
       " 'to',\n",
       " 'install',\n",
       " 'speed',\n",
       " 'the',\n",
       " 'cameras',\n",
       " 'along',\n",
       " 'the',\n",
       " 'road',\n",
       " ',']"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91115fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dcde6210",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "output, hn = rnn(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b2c95f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "fb97cd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([0,3,1,2,3,1,4,6,6,6])\n",
    "c = a == 1\n",
    "c = c.nonzero()\n",
    "c[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "8292a7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 5, 3])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3,5,7)\n",
    "x\n",
    "y = torch.transpose(x, 1, 3)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17525318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
